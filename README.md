# 开源预训练语言模型合集

这是由追一科技有限公司推出的一个预训练模型合集，主要发布自研的预训练语言模型，推动自然语言处理技术的进步。预训练语言模型通过在大规模文本上进行预训练，可以作为下游自然语言处理任务的模型参数或者模型输入以提高模型的整体性能。

## 模型概览

以下是我们目前公开发布的模型概览：

| 名称           | 数据来源     | 训练数据大小 | 词表大小 | 模型大小 | 下载地址 |
| ------------  | ----------- | -----------| -------- | -------- | -------- |
| RoBERTa Tiny  | 百科,新闻 等  |     35G    | 21128    | 29MB | [百度网盘](https://pan.baidu.com/s/1BWhzP8K9rHi2uWtOUQoX5Q)(beum) |
| RoBERTa Small | 百科,新闻 等  |     35G    | 21128  | 52MB  | [百度网盘](https://pan.baidu.com/s/1uGfQmX1Kxcv_cXTVsvxTsQ)(6xhq) |
| SimBERT Base  | [百度知道](http://zhidao.baidu.com/) | 2200万相似句组 | 21128  | 371MB  | [百度网盘](https://pan.baidu.com/s/1AqoD49xkeAO4KHsBrmFFOA)(hjqc) |

## 模型详情

此处对每个模型进行较为详细的介绍

### RoBERTa Tiny

### RoBERTa Small

### SimBERT Base

## 模型训练

## 如何引用

Bibtex：

```tex
@techreport{zhuiyipretrainedmodels,
  title={Open Language Pre-trained Model Zoo - ZhuiyiAI},
  author={Jianlin Su},
  year={2020},
  url = "https://github.com/ZhuiyiAI/pretrained-models",
}
```

## 联系我们

邮箱：ai@wezhuiyi.com

## 相关链接

追一科技：https://zhuiyi.ai
