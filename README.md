# 开源预训练语言模型合集

这是由追一科技有限公司推出的一个预训练模型合集，主要发布自研的预训练语言模型，推动自然语言处理技术的进步。预训练语言模型通过在大规模文本上进行预训练，可以作为下游自然语言处理任务的模型参数或者模型输入以提高模型的整体性能。

## 模型概览

以下是我们目前公开发布的模型概览：

| 名称           | 数据来源     | 训练数据大小 | 词表大小 | 模型大小 | 下载地址 |
| ------------  | ----------- | ------------ | -------- | -------- | -------- |
| RoBERTa Tiny  | 百科 + 新闻  |   35G      | 21128    | 29MB | [点我下载](https://zhuiyi.ai) |
| RoBERTa Small | 百科 + 新闻  |   35G      | 21128  | 52MB  | [点我下载](https://zhuiyi.ai) |
| SimBERT Base  | [百度知道](http://zhidao.baidu.com/) | 2200万相似句组  | 21128  | 371MB  | [点我下载](https://zhuiyi.ai) |


